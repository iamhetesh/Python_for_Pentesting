from flask import Flask, render_template, request, send_file
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.callbacks import LambdaCallback
from keras.models import Sequential
from tensorflow.keras.optimizers import SGD
import matplotlib.pyplot as plt
from keras.layers import Dense, Dropout
from sklearn.preprocessing import LabelEncoder, StandardScaler
from keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

app = Flask(__name__, template_folder="path/to/directory")

@app.route('/path/to/html_files')
def index():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    global epoch_history
    global plot_waveform
    global fig
    global X_test
    global new_x
    global model
    global rounded_predictions
    global names
    file = request.files["dataset"]
    data = pd.read_csv(file, sep='|')
    x = data.drop(['unnecessary_columns'], axis=1).values
    y = data['legitimacy_column'].values # Column which contains the status of file such as '1' for benign and '0' for malware 
    names = data['name_column'].values
    new_x = LabelEncoder().fit_transform(x.ravel()).reshape(*x.shape) # Reshaping to minimize the loss function during training also converts 2D array of categorical data in to 2D array of numerical data 
    new_y = LabelEncoder().fit_transform(y)
    reshaped_x = new_x.reshape((new_x.shape[0], -1))
    norm_x = StandardScaler().fit_transform(reshaped_x)
    X_train, X_test, y_train, y_test = train_test_split(norm_x, new_y, test_size=0.2, random_state=42, shuffle=True)

    model = Sequential()
    model.add(Dense(256, input_dim=x.shape[1], activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    sgd = SGD(learning_rate = 0.001, momentum = 0.9)
    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy']) # To compile binary classification tasks

    early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1)
    checkpointer = ModelCheckpoint(filepath='best_weights_1.h5', verbose=1, save_best_only=True) 

    def plot_waveform(epoch_history):
        global fig
        loss = [x['loss'] for x in epoch_history]
        val_loss = [x['val_loss'] for x in epoch_history]
        acc = [x['accuracy'] for x in epoch_history]
        val_acc = [x['val_accuracy'] for x in epoch_history]

        fig, axs = plt.subplots(2, 1, figsize=(12, 8))
        axs[0].plot(loss, label='Training Loss')
        axs[0].plot(val_loss, label='Validation Loss')
        axs[0].set_title('Training and Validation Loss')
        axs[0].legend()

        axs[1].plot(acc, label='Training Accuracy')
        axs[1].plot(val_acc, label='Validation Accuracy')
        axs[1].set_title('Training and Validation Accuracy')
        axs[1].legend()
        filename = 'plot.png'

        fig.savefig(filename)
        return filename

    epoch_history = []
    epoch_callback = LambdaCallback(
        on_epoch_end=lambda epoch, logs: [epoch_history.append(logs), plot_waveform(epoch_history)]) 

    #epoch_waveform = LambdaCallback(on_epoch_end=lambda epoch, logs: [plot_waveform(epoch_history)])

    model.fit(X_train, y_train, epochs=300, batch_size=32, callbacks=[early_stopping, checkpointer, epoch_callback], validation_data=(X_test, y_test))
    model.load_weights('best_weights_1.h5')

    score = model.evaluate(X_test, y_test, verbose=0)
    training_loss = score[0]
    training_accuracy = score[1]

    predictions = model.predict(X_test)

    rounded_predictions = np.round(predictions)

    cm = confusion_matrix(y_test, rounded_predictions)
    precision = precision_score(y_test, rounded_predictions)
    recall = recall_score(y_test, rounded_predictions)
    f1 = f1_score(y_test, rounded_predictions)

    return render_template('predict.html', training_loss=training_loss, training_accuracy=training_accuracy, epoch_history=epoch_history, cm=cm, plot_path='path/to/plot.png',precision=precision, recall=recall, f1=f1)

'''
# The following lines are usually not required during training phase as the results could have many misclassifications. But for the DNN to learn the characteristics of both types of files in order to accurately distinguish between them in the future continue with the below code.
@app.route('/group', methods=['POST'])
def group():
    malware_files = []
    legit_files = []
    for i in range(len(rounded_predictions)):
        if rounded_predictions[i] == 0:
            malware_files.append(names[i])
        else:
            legit_files.append(names[i])

    return render_template('group.html', malware_files=malware_files, legit_files=legit_files)
'''

@app.route('/plot')
def plot():
    filename = plot_waveform(epoch_history)
    return send_file(filename, mimetype='image/png') # Plotting the performance metrics in waveform


if __name__ == "__main__":
    app.run(debug=True)
